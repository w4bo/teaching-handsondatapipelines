{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/w4bo/teaching-handsondatapipelines/blob/main/materials/15-BreastCancer.solution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "ae0f114b-aa26-5802-345f-83fd12c570fe",
        "id": "BT1cUdptTRIv"
      },
      "source": [
        "# The `BreastCancer` challenge\n",
        "\n",
        "### Goal\n",
        "\n",
        "It is your job to predict the `diagnosis` for each data item.\n",
        "\n",
        "### Metric\n",
        "\n",
        "Submissions are evaluated using the accuracy score. When splitting train and test datasets, the test dataset should contain 30% of the data.\n",
        "\n",
        "### Requirements\n",
        "\n",
        "You are allowed to use `numpy`, `pandas`, `matplotlib`, `sns`, and `sk-learn` Python libraries. You can import any model from `sk-learn`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "e3200e6e-62d4-1d74-496b-c5197a574dcb",
        "id": "chtXn7o-TRIy"
      },
      "outputs": [],
      "source": [
        "# Import the libraries used for machine learning\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv), data manipulation as in SQL\n",
        "import matplotlib.pyplot as plt # this is used for the plot the graph \n",
        "import seaborn as sns # used for plot interactive graph. I like it most for plot\n",
        "%matplotlib inline\n",
        "from sklearn.model_selection import train_test_split # to split the data into two parts\n",
        "from sklearn.model_selection import KFold # use for cross validation\n",
        "from sklearn.model_selection import GridSearchCV # for tuning parameter\n",
        "from sklearn.ensemble import RandomForestClassifier # for random forest classifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn import metrics # for the check the error and accuracy of the model\n",
        "import random\n",
        "import os\n",
        "\n",
        "# SEED all random generators\n",
        "seed = 42\n",
        "random.seed(seed)\n",
        "os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "np.random.seed(seed)\n",
        "\n",
        "# read the data\n",
        "# df = pd.read_csv(\"datasets/breastcancer.csv\")\n",
        "df = pd.read_csv(\"https://raw.githubusercontent.com/w4bo/teaching-handsondatapipelines/main/materials/datasets/breastcancer.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "htswCay8TRI0"
      },
      "source": [
        "## Data understanding\n",
        "\n",
        "Hints\n",
        "\n",
        "- There are 569 observations with 30 features each\n",
        "- Each observation is labelled with a `diagnosis`\n",
        "\n",
        "Take a first glance to the dataset\n",
        "- Do we consider all features?\n",
        "- Are there null values?\n",
        "- Which are the attribute types?\n",
        "- Which are the attribute ranges?\n",
        "- How many labels?\n",
        "- Are classes unbalanced?\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "7036d299-0057-db0a-d892-fe212c0d612c",
        "id": "nVcG-ZNBTRI1"
      },
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "1109ea03-5b73-25fa-72ca-6695de4b0c5b",
        "id": "lmVbuHfuTRI2"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dMmSLBGwTRI3"
      },
      "source": [
        "### Feature semantics\n",
        "\n",
        "Hint:\n",
        "- id of the observation\n",
        "- diagnosis (M = malignant, B = benign)\n",
        "- Ten real-valued features are computed for each cell nucleus:\n",
        "    - radius (mean of distances from center to points on the perimeter)\n",
        "    - texture (standard deviation of gray-scale values)\n",
        "    - perimeter\n",
        "    - area\n",
        "    - smoothness (local variation in radius lengths)\n",
        "    - compactness (perimeter^2 / area - 1.0)\n",
        "    - concavity (severity of concave portions of the contour)\n",
        "    - concave points (number of concave portions of the contour)\n",
        "    - symmetry\n",
        "    - fractal dimension (\"coastline approximation\" - 1)\n",
        "\n",
        "`*_mean`: the means of all cells\n",
        "\n",
        "`*_se`: standard error of all cells\n",
        "\n",
        "`*_worst`: the worst cell\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pcK_SW4STRI4",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3nYDx_b4TRI5"
      },
      "outputs": [],
      "source": [
        "df['diagnosis'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VGWUqoXbTRI6"
      },
      "outputs": [],
      "source": [
        "df['diagnosis'].value_counts().plot(kind=\"bar\", label=\"Count\", legend=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZYnY2MwITRI7"
      },
      "outputs": [],
      "source": [
        "sns.countplot(data=df, x='diagnosis', hue='diagnosis')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ff4gyS0VTRI7"
      },
      "source": [
        "### Summing up\n",
        "\n",
        "| Question | Answer | Do we need action? |\n",
        "| -        | -      | - |\n",
        "| Are there null values? | Yes | No need for imputation, drop the column |\n",
        "| Which are the attribute types? | All attributes are numeric but `diagnosis` | Encode diagnosis | \n",
        "| Which are the attribute ranges? | Attribute ranges are similar | We could apply normalization |\n",
        "| How many labels? | 2 | - |\n",
        "| Are classes unbalanced? | No, classess are almost equally distributed | No rebalancing |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "9041739c-1d90-970b-55ec-224ed821898a",
        "id": "R6Z5LqQnTRI8"
      },
      "source": [
        "## Data preprocessing\n",
        "\n",
        "Drop the unnecessary columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "9ec57be7-c20b-5895-2f20-0f32651b3f79",
        "id": "H8JkXXUmTRI9"
      },
      "outputs": [],
      "source": [
        "# `Unnamed:32` has 0 non null objects, all values are null. Drop the column\n",
        "df.drop([\"id\", \"Unnamed: 32\"], axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "dbdd0bf6-da03-c390-0e7a-f6b181f8e127",
        "id": "NKpu3FSMTRI-"
      },
      "outputs": [],
      "source": [
        "# map the diagnosis column to numeric\n",
        "df['diagnosis'] = df['diagnosis'].map({'M': 1, 'B': 0})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LYWAmqHSTRI-"
      },
      "source": [
        "### Data visualization\n",
        "\n",
        "- Check the attribute's distribution\n",
        "- Check the relationships between attributes (e.g., the correlation). Should we keep all attributes?\n",
        "\n",
        "For now, let's just focus on `*_mean` attributes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "68f07b98-c05a-f3e6-7dbe-8e39ab7d13f6",
        "id": "tHFUruycTRI_"
      },
      "outputs": [],
      "source": [
        "# Data can be divided into three parts (i.e., families of columns)\n",
        "features_mean = list(df.columns[1:11]) + [\"diagnosis\"]\n",
        "features_se = list(df.columns[11:20]) + [\"diagnosis\"]\n",
        "features_worst = list(df.columns[21:31]) + [\"diagnosis\"]\n",
        "print(\"features_mean: \" + str(features_mean))\n",
        "print(\"features_se: \" + str(features_se))\n",
        "print(\"features_worst: \" + str(features_worst))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vDkwDZA7TRI_"
      },
      "outputs": [],
      "source": [
        "df[features_mean].hist(bins=50, figsize=(20,15))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cbFmlGsCTRJA"
      },
      "outputs": [],
      "source": [
        "g = sns.pairplot(df[features_mean], hue='diagnosis', markers='+')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k3HEdM32TRJB"
      },
      "outputs": [],
      "source": [
        "# df[features_se].hist(bins=50, figsize=(20,15))\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ksgt_w4pTRJB"
      },
      "outputs": [],
      "source": [
        "# g = sns.pairplot(df[features_se], hue='diagnosis', markers='+')\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cgi2_xXQTRJB"
      },
      "outputs": [],
      "source": [
        "#  df[features_worst].hist(bins=50, figsize=(20,15))\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CvsmQ46eTRJB",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# g = sns.pairplot(df[features_worst], hue='diagnosis', markers='+')\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HnCjWeK0TRJC",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "df = df[features_mean]\n",
        "from scipy.stats import pearsonr\n",
        "rho = df.corr(method ='pearson')\n",
        "pval = df.corr(method=lambda x, y: pearsonr(x, y)[1]) - np.eye(*rho.shape)\n",
        "p = pval.applymap(lambda x: ''.join(['*' for t in [0.01, 0.05, 0.1] if x <= t]))\n",
        "rho.round(2).astype(str) + p"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U10eQsDFTRJC"
      },
      "outputs": [],
      "source": [
        "min_corr = 0.3\n",
        "kot = rho[(abs(rho) >= min_corr) & (rho < 1)]\n",
        "plt.figure(figsize=(14, 14))\n",
        "sns.heatmap(kot, cmap=sns.color_palette(\"coolwarm\", as_cmap=True), annot=True, fmt= '.2f',annot_kws={'size': 15})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X4wM7dQETRJC"
      },
      "source": [
        "### Should we drop some attributes?\n",
        "\n",
        "- `radius_mean`, `perimeter_mean`, and `area_mean` are highly correlated, keep `permiter`\n",
        "- `compactness_mean`, `concavity_mean` and `concavepoint_mean` are highly correlated, keep `compactness_mean`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "fcd92fe8-fb89-d377-f135-c053e562e820",
        "id": "LLgqah5TTRJD"
      },
      "outputs": [],
      "source": [
        "# now these are the variables that we will use for prediction\n",
        "prediction_var = ['texture_mean', 'perimeter_mean', 'smoothness_mean', 'compactness_mean', 'symmetry_mean']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8u6cgPY-TRJD"
      },
      "source": [
        "## Modeling with scikit-learn\n",
        "\n",
        "Preparing the dataset for the ML pipeline.\n",
        "- X: the dataset\n",
        "- y: the labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QnjR4x98TRJE"
      },
      "outputs": [],
      "source": [
        "def set_dataset(feature_list, normalize=False):\n",
        "    X = df[[x for x in feature_list if x != \"diagnosis\"]]\n",
        "    y = df['diagnosis']\n",
        "\n",
        "    if normalize:\n",
        "      X = (X - X.mean()) / X.std()\n",
        "    \n",
        "    # print(X.head())\n",
        "    print(X.shape)\n",
        "    # print(y.head())\n",
        "    print(y.shape)\n",
        "    return X, y\n",
        "\n",
        "X, y = set_dataset(prediction_var, True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v3l2KpHITRJE"
      },
      "outputs": [],
      "source": [
        "X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FsxC9-lrTRJE"
      },
      "outputs": [],
      "source": [
        "y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o2mVnzICTRJF"
      },
      "source": [
        "## Split the dataset into a training set and a testing set\n",
        "\n",
        "### Advantages\n",
        "- By splitting the dataset pseudo-randomly into a two separate sets, we can train using one set and test using another.\n",
        "- This ensures that we won't use the same observations in both sets.\n",
        "- More flexible and faster than creating a model using all of the dataset for training.\n",
        "\n",
        "### Disadvantages\n",
        "- The accuracy scores for the testing set can vary depending on what observations are in the set. \n",
        "- This disadvantage can be countered using k-fold cross-validation.\n",
        "\n",
        "### Notes\n",
        "- The accuracy score of the models depends on the observations in the testing set, which is determined by the seed of the pseudo-random number generator (random_state parameter).\n",
        "- As a model's complexity increases, the training accuracy (accuracy you get when you train and test the model on the same data) increases.\n",
        "- If a model is too complex or not complex enough, the testing accuracy is lower.\n",
        "- For KNN models, the value of k determines the level of complexity. A lower value of k means that the model is more complex."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "da2eaf5c-6f86-b320-a591-fb7b7e0fb12c",
        "id": "WOdHckubTRJF"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cdAxfhg3ufih"
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "pca = PCA(n_components=2)\n",
        "result = pca.fit_transform(X_train)\n",
        "\n",
        "plt.scatter(\n",
        "    x=result[:,0], \n",
        "    y=result[:,1] , \n",
        "    c=y_train,\n",
        "    cmap='viridis'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MZ56qainxIjR"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(projection='3d')\n",
        "\n",
        "pca = PCA(n_components=3)\n",
        "result = pca.fit_transform(X_train)\n",
        "\n",
        "ax.scatter(\n",
        "    xs=result[:,0], \n",
        "    ys=result[:,1], \n",
        "    zs=result[:,2], \n",
        "    c=y_train,\n",
        "    cmap='viridis'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5pAVxc66vXTA"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import IsolationForest\n",
        "clf = IsolationForest()\n",
        "clf.fit(X_train)\n",
        "is_outlier = clf.predict(X_train)\n",
        "\n",
        "plt.scatter(\n",
        "    x=result[:,0], \n",
        "    y=result[:,1], \n",
        "    s=[10 if x > 0 else 20 for x in is_outlier],\n",
        "    c=is_outlier,\n",
        "    cmap='viridis'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "viO31voXyyEJ"
      },
      "outputs": [],
      "source": [
        "# all parameters not specified are set to their defaults\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "logisticRegr = LogisticRegression()\n",
        "logisticRegr.fit(X_train, y_train)\n",
        "y_pred = logisticRegr.predict(X_test)\n",
        "metrics.accuracy_score(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZLv9sV-TRJF"
      },
      "source": [
        "Fit your model and try it with several parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "teuq4BLdTRJG"
      },
      "outputs": [],
      "source": [
        "def fit_knn(X_train, y_train, X_test, y_test):\n",
        "    # experimenting with different k values\n",
        "    k_range = list(range(1, 30))\n",
        "    scores = []\n",
        "    for k in k_range:\n",
        "        knn = KNeighborsClassifier(n_neighbors=k)\n",
        "        knn.fit(X_train, y_train)\n",
        "        y_pred = knn.predict(X_test)\n",
        "        scores.append(metrics.accuracy_score(y_test, y_pred))\n",
        "\n",
        "    plt.plot(k_range, scores)\n",
        "    plt.xticks(k_range)\n",
        "    plt.xlabel('Value of k for KNN')\n",
        "    plt.ylabel('Accuracy Score')\n",
        "    plt.title('k-Nearest-Neighbors')\n",
        "    plt.show()\n",
        "    return y_pred\n",
        "\n",
        "fit_knn(X_train, y_train, X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQT2U9d4TRJH"
      },
      "source": [
        "What if I compare the model vs the model trained on the training set only?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QcOo7IvuTRJH"
      },
      "outputs": [],
      "source": [
        "fit_knn(X_train, y_train, X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Sr5Aor6TRJH"
      },
      "source": [
        "What if I choose a more complex model?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "4936a3a9-e7fd-81a1-1aec-a267224569d5",
        "id": "4-h7qsNlTRJH",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "def fit_forest(X_train, y_train, X_test, y_test):\n",
        "    model=RandomForestClassifier(n_estimators=100) # a simple random forest model\n",
        "    model.fit(X_train, y_train) # now fit our model for training data\n",
        "    y_pred = model.predict(X_test) # predict for the test data\n",
        "    # prediction will contain the predicted value by our model predicted values of dignosis column for test inputs\n",
        "    print(\"Accuracy: \" + str(metrics.accuracy_score(y_pred, y_test))) # to check the accuracy\n",
        "    # here we will use accuracy measurement between our predicted value and our test output values\n",
        "    featimp = pd.Series(model.feature_importances_, index=X_train.columns).sort_values(ascending=False)\n",
        "    print(\"\\nFeatures sorted by descending importance:\")\n",
        "    print(featimp) # this is the property of Random Forest classifier that it provide us the importance of the features used\n",
        "\n",
        "fit_forest(X_train, y_train, X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "87950903-844c-058d-23d5-2d55ae58de75",
        "id": "nfF19_ryTRJI"
      },
      "source": [
        "Now lets do this for all `feature_mean` so that from Random forest we can get the feature which are important"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "20b8aaf5-677c-a2af-c998-dfd5fa713115",
        "id": "D2El79tdTRJI"
      },
      "outputs": [],
      "source": [
        "X, y = set_dataset(features_mean, True) # taking all features\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
        "fit_forest(X_train, y_train, X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GAZi3pQYTRJJ"
      },
      "source": [
        "What if we use cross-validation?\n",
        "\n",
        "https://scikit-learn.org/stable/modules/cross_validation.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "igPZRWOTTRJJ"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "def cv(model, X, y):\n",
        "    scores = cross_val_score(model, X, y, cv=5)\n",
        "    print(\"Scores: \" + str(scores))\n",
        "    print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))\n",
        "\n",
        "model = RandomForestClassifier(n_estimators=100)\n",
        "cv(model, X, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "USMW2mrKTRJJ"
      },
      "outputs": [],
      "source": [
        "model = KNeighborsClassifier(n_neighbors=10)\n",
        "cv(model, X, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0bNd9ufKTRJK"
      },
      "source": [
        "Grid search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N30UoOv6TRJK"
      },
      "outputs": [],
      "source": [
        "# lets Make a function for Grid Search CV\n",
        "def gridsearch_cv(model,param_grid, X_train, y_train):\n",
        "    clf = GridSearchCV(model, param_grid, cv=5, scoring=\"accuracy\", verbose=1, n_jobs=2)\n",
        "    clf.fit(X_train, y_train)\n",
        "    print(\"The best parameters are:\")\n",
        "    print(clf.best_params_)\n",
        "    print(\"The best estimator is \" + str(clf.best_estimator_))\n",
        "    print(\"The best score is \" + str(clf.best_score_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "f5238051-7292-5a2a-f255-cd68c9797125",
        "id": "BbX4bhZnTRJL"
      },
      "outputs": [],
      "source": [
        "model = KNeighborsClassifier()\n",
        "\n",
        "k_range = list(range(1, 30, 3))\n",
        "leaf_size = list(range(1, 30, 3))\n",
        "param_grid = {'n_neighbors': k_range, 'leaf_size': leaf_size} #, 'weights': ['uniform', 'distance']}\n",
        "\n",
        "gridsearch_cv(model, param_grid, X, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "fff56e83-608f-bee1-8cdf-d75b07cab36a",
        "id": "zrO5o46STRJL"
      },
      "outputs": [],
      "source": [
        "model = RandomForestClassifier()\n",
        "\n",
        "estimator_range = [10, 50, 100]\n",
        "param_grid = {'n_estimators': estimator_range}\n",
        "\n",
        "gridsearch_cv(model, param_grid, X, y)"
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "colab": {
      "name": "04-BreastCancer.solution.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}